# .github/workflows/mlops_pipeline.yml - FINAL COMPLETE VERSION

name: KlinikOps MLOps Pipeline (CI/CD/DVC/ACI)

on:
  push:
    branches: []
  workflow_dispatch:

env:
  RG_NAME: ClinicOps-RG
  LOCATION: westeurope
  STORAGE_ACCOUNT: clinicopsdvcstorage2025 
  CONTAINER_NAME: clinicops-dvc 
  
jobs:
  full-mlops-workflow:
    runs-on: ubuntu-latest
    outputs:
      run_id: ${{ steps.train.outputs.MLFLOW_RUN_ID }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install dvc[azure]
          pip install azure-storage-blob 

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # --- DVC PULL DATA ---
      - name: DVC Pull Data
        env:
          AZURE_STORAGE_ACCOUNT: ${{ env.STORAGE_ACCOUNT }}
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
        run: |
          echo "Configuring DVC remote..."
          
          # Create DVC remote
          dvc remote add -d myremote azure://${{ env.CONTAINER_NAME }}/data || true
          dvc remote modify myremote account_name $AZURE_STORAGE_ACCOUNT
          
          # DVC will automatically use AZURE_STORAGE_KEY from environment
          
          echo "Attempting DVC pull..."
          dvc pull -v
          
          echo "âœ… Data directory check:"
          ls -lh data/raw/

      # --- TRAIN MODEL ---
      - name: Run Data Processing and Train Model
        id: train
        env:
          PYTHONPATH: .
          AZURE_STORAGE_ACCOUNT: ${{ env.STORAGE_ACCOUNT }}
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
        run: |
          python scripts/data_processing.py
          
          # train.py returns Run ID
          RUN_ID=$(python scripts/train.py) 
          
          echo "MLFLOW_RUN_ID=$RUN_ID" >> $GITHUB_OUTPUT

      # --- UPLOAD ARTIFACTS ---
      - name: Upload MLflow Artifacts and Pointer to Azure
        env:
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
          AZURE_STORAGE_ACCOUNT: ${{ env.STORAGE_ACCOUNT }}
        run: |
          RUN_ID=${{ steps.train.outputs.MLFLOW_RUN_ID }}
          
          echo "Uploading artifacts for Run ID: $RUN_ID"
          
          # Use Python script for reliable upload
          python - <<'EOF'
          import os
          import glob
          from azure.storage.blob import ContainerClient
          
          account_name = os.getenv('AZURE_STORAGE_ACCOUNT')
          account_key = os.getenv('AZURE_STORAGE_KEY')
          container_name = 'clinicops-dvc'
          
          print(f"Connecting to {account_name}/{container_name}")
          
          container_client = ContainerClient(
              account_url=f"https://{account_name}.blob.core.windows.net",
              container_name=container_name,
              credential=account_key
          )
          
          # Upload mlruns directory
          uploaded_count = 0
          for filepath in glob.glob('mlruns/**/*', recursive=True):
              if os.path.isfile(filepath):
                  blob_name = filepath.replace('\\', '/')
                  try:
                      with open(filepath, 'rb') as data:
                          blob_client = container_client.get_blob_client(blob_name)
                          blob_client.upload_blob(data, overwrite=True)
                          uploaded_count += 1
                  except Exception as e:
                      print(f"Failed to upload {blob_name}: {e}")
          
          print(f"âœ… Uploaded {uploaded_count} MLflow files")
          
          # Upload pointer file
          with open('latest_run_id.txt', 'rb') as f:
              blob_client = container_client.get_blob_client('latest_model_run.txt')
              blob_client.upload_blob(f, overwrite=True)
              print("âœ… Uploaded pointer file: latest_model_run.txt")
          EOF

  deploy-api-to-aci:
    needs: full-mlops-workflow
    runs-on: ubuntu-latest
    environment: Production 
    env:
      ACR_LOGIN_SERVER: ${{ secrets.AZURE_CR_LOGIN_SERVER }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
          
      - name: Docker Login
        uses: docker/login-action@v3
        with:
          registry: ${{ env.ACR_LOGIN_SERVER }}
          username: ${{ secrets.AZURE_CR_USERNAME }}
          password: ${{ secrets.AZURE_CR_PASSWORD }}
          
      - name: Build and Push Docker Image
        uses: docker/build-push-action@v5 
        with:
          context: .
          push: true
          tags: ${{ env.ACR_LOGIN_SERVER }}/klinikops-model:${{ github.sha }}
          
      - name: Deploy to ACI
        env:
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
          RG_NAME: ${{ env.RG_NAME }}
          STORAGE_ACCOUNT: ${{ env.STORAGE_ACCOUNT }}
          ACR_LOGIN_SERVER: ${{ env.ACR_LOGIN_SERVER }}
          ACR_USERNAME: ${{ secrets.AZURE_CR_USERNAME }}
          ACR_PASSWORD: ${{ secrets.AZURE_CR_PASSWORD }}
        run: |
          SHA_SHORT=$(echo ${{ github.sha }} | cut -c1-8)
          ACI_NAME="ci-api-$SHA_SHORT" 
          IMAGE_NAME="$ACR_LOGIN_SERVER/klinikops-model:${{ github.sha }}"
          
          # Create connection string for MLflow
          CONN_STRING="DefaultEndpointsProtocol=https;AccountName=$STORAGE_ACCOUNT;AccountKey=$AZURE_STORAGE_KEY;EndpointSuffix=core.windows.net"

          echo "ðŸš€ Deploying container: $ACI_NAME"
          
          az container create \
            --resource-group $RG_NAME \
            --name $ACI_NAME \
            --image $IMAGE_NAME \
            --location westeurope \
            --dns-name-label $ACI_NAME \
            --registry-login-server $ACR_LOGIN_SERVER \
            --registry-username $ACR_USERNAME \
            --registry-password $ACR_PASSWORD \
            --ports 80 \
            --cpu 1 \
            --memory 1.5 \
            --os-type Linux \
            --restart-policy Always \
            --environment-variables \
              AZURE_STORAGE_ACCOUNT="$STORAGE_ACCOUNT" \
              AZURE_STORAGE_KEY="$AZURE_STORAGE_KEY" \
              AZURE_STORAGE_CONNECTION_STRING="$CONN_STRING"
          
          echo "âœ… Deployment complete"
          
          # Get container IP
          CONTAINER_IP=$(az container show \
            --resource-group $RG_NAME \
            --name $ACI_NAME \
            --query ipAddress.ip -o tsv)
          
          echo "=========================================="
          echo "ðŸŒ API URL: http://${CONTAINER_IP}"
          echo "ðŸ¥ Health: http://${CONTAINER_IP}/health"
          echo "ðŸ” Debug: http://${CONTAINER_IP}/debug"
          echo "ðŸ“š Docs: http://${CONTAINER_IP}/docs"
          echo "=========================================="
          
          # Wait for container to start
          echo "â³ Waiting 30 seconds for startup..."
          sleep 30
          
          # Test health endpoint
          echo "ðŸ§ª Testing health endpoint..."
          curl -s "http://${CONTAINER_IP}/health" || echo "Health check pending..."